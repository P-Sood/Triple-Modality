{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, \"/\".join(os.getcwd().split(\"/\")[:-1]))\n",
    "__package__ = \"LoadModels_NoteBooks\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeerak.talat/.conda/envs/featuregen/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.global_functions import arg_parse, Metrics, MySampler, NewCrossEntropyLoss\n",
    "from transformers import AutoModel\n",
    "from  SingleModels.models.whisper import WhisperForEmotionClassification\n",
    "from  SingleModels.whisper_nn import prepare_dataloader\n",
    "import wandb\n",
    "from utils.trainer import Trainer\n",
    "from utils.data_loaders import BertDataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in Models/Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "args[\"dropout\"] =  0\n",
    "args[\"output_dim\"] =  7\n",
    "args[\"dataset\"] =  \"meld\"\n",
    "args[\"learn_PosEmbeddings\"] =  False\n",
    "args[\"num_layers\"] =  12\n",
    "\n",
    "whisper = WhisperForEmotionClassification(args)\n",
    "path = \"WhisperStart/qgl7153h/toasty-sweep-9/best.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whisper_state_dict = torch.load(f\"../../TAV_Train/{path}\" , map_location=torch.device('cpu'))['model_state_dict']\n",
    "whisper.load_state_dict(whisper_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below is for encoder only load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_state_dict = torch.load(f\"../../TAV_Train/{path}\" , map_location=torch.device('cpu'))['model_state_dict']\n",
    "roberta_state_dict = whisper.state_dict()\n",
    "\n",
    "for key in roberta_state_dict.keys():\n",
    "    bert_key = 'bert.' + key  # prepend 'bert.' to the key\n",
    "    if bert_key in bert_state_dict:\n",
    "        # print(f\"Loading {bert_key}\"  , flush = True)\n",
    "        roberta_state_dict[key] = bert_state_dict[bert_key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check load properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0754, -0.0241, -0.0955,  ...,  0.0763, -0.1577,  0.0778])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_state_dict['videomae.encoder.layer.23.output.dense.bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(roberta_state_dict['encoder.layer.23.output.dense.bias'] == bert_state_dict['videomae.encoder.layer.23.output.dense.bias']).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WhisperForEmotionClassification(\n",
       "  (whisper): WhisperForAudioClassification(\n",
       "    (encoder): WhisperEncoder(\n",
       "      (conv1): Conv1d(80, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv2): Conv1d(1024, 1024, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (embed_positions): Embedding(1500, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-23): 24 x WhisperEncoderLayer(\n",
       "          (self_attn): WhisperAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (projector): Linear(in_features=1024, out_features=256, bias=True)\n",
       "    (classifier): Linear(in_features=256, out_features=2, bias=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0, inplace=False)\n",
       "  (linear1): Linear(in_features=1024, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whisper.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WhisperEncoder(\n",
       "  (conv1): Conv1d(80, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (conv2): Conv1d(1024, 1024, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "  (embed_positions): Embedding(1500, 1024)\n",
       "  (layers): ModuleList(\n",
       "    (0-23): 24 x WhisperEncoderLayer(\n",
       "      (self_attn): WhisperAttention(\n",
       "        (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (activation_fn): GELUActivation()\n",
       "      (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "      (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whisper.whisper.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 'surprise',\n",
       " 3: 'anger',\n",
       " 0: 'neutral',\n",
       " 1: 'joy',\n",
       " 4: 'sadness',\n",
       " 6: 'fear',\n",
       " 5: 'disgust'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = \"../data/meld.pkl\"\n",
    "df = pd.read_pickle(f\"{name}\")\n",
    "number_index = \"emotion\"\n",
    "label_index = \"emotion_label\"\n",
    "label2id = (\n",
    "    df.drop_duplicates(label_index).set_index(label_index).to_dict()[number_index]\n",
    ")\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are we running on mustard? False\n"
     ]
    }
   ],
   "source": [
    "df_test = prepare_dataloader(\n",
    "        df[df['split'] == \"test\"], name, 1, \"emotion\", 2 , check=\"test\"\n",
    "    )\n",
    "Metric = Metrics(num_classes=len(id2label), id2label=id2label, rank=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test:   0%|          | 0/2608 [00:00<?, ?it/s]2023-11-26 06:38:12.395510: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-26 06:38:13.815661: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "test: 100%|██████████| 2608/2608 [1:31:58<00:00,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " in test \n",
      " Confusion Matrix = \n",
      "tensor([[651, 238,  52, 232,  53,  11,  19],\n",
      "        [108, 189,  20,  58,  12,  10,   5],\n",
      "        [ 63,  56,  87,  52,  10,   6,   7],\n",
      "        [ 66,  46,  19, 192,  11,   5,   5],\n",
      "        [ 52,  36,  12,  53,  46,   4,   5],\n",
      "        [  9,  13,   4,  28,   6,   4,   3],\n",
      "        [ 15,   8,   0,  16,   6,   2,   3]]) \n",
      "\n",
      "\n",
      " in test \n",
      " Acc = \n",
      "0.44938650727272034 \n",
      "\n",
      "\n",
      " in test \n",
      " Prec = \n",
      "0.3184402287006378 \n",
      "\n",
      "\n",
      " in test \n",
      " Rec = \n",
      "0.31386637687683105 \n",
      "\n",
      "\n",
      " in test \n",
      " F1Weighted = \n",
      "0.45675623416900635 \n",
      "\n",
      "\n",
      " in test \n",
      " F1Macro = \n",
      "0.30369332432746887 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "You must call wandb.init() before wandb.log()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m/home/zeerak.talat/trimodal/LoadModels_NoteBooks/loadWhisper.ipynb Cell 16\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcscc/home/zeerak.talat/trimodal/LoadModels_NoteBooks/loadWhisper.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(big_batch\u001b[39m=\u001b[39m\u001b[39m23\u001b[39m , num_steps\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bcscc/home/zeerak.talat/trimodal/LoadModels_NoteBooks/loadWhisper.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mevaluate(whisper, df_test, Metric)\n",
      "File \u001b[0;32m/l/users/zeerak.talat/Triple-Modality/utils/trainer.py:450\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, model, test_dataloader, Metric)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate\u001b[39m(\u001b[39mself\u001b[39m , model, test_dataloader, Metric):\n\u001b[0;32m--> 450\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalidate(test_dataloader, model, \u001b[39mNone\u001b[39;49;00m, Metric, name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtest\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m/l/users/zeerak.talat/Triple-Modality/utils/trainer.py:297\u001b[0m, in \u001b[0;36mTrainer.validate\u001b[0;34m(self, val_dataloader, model, criterion, Metric, name)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[39mdel\u001b[39;00m val_input\n\u001b[1;32m    296\u001b[0m         \u001b[39mdel\u001b[39;00m val_label\n\u001b[0;32m--> 297\u001b[0m     weightedF1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlog(\n\u001b[1;32m    298\u001b[0m         Metric,\n\u001b[1;32m    299\u001b[0m         total_loss_val \u001b[39m/\u001b[39;49m \u001b[39mlen\u001b[39;49m(val_dataloader) \u001b[39mif\u001b[39;49;00m criterion \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39m0\u001b[39;49m,\n\u001b[1;32m    300\u001b[0m         name,\n\u001b[1;32m    301\u001b[0m     )\n\u001b[1;32m    302\u001b[0m \u001b[39mreturn\u001b[39;00m total_loss_val \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(val_dataloader), weightedF1\n",
      "File \u001b[0;32m/l/users/zeerak.talat/Triple-Modality/utils/trainer.py:481\u001b[0m, in \u001b[0;36mTrainer.log\u001b[0;34m(self, Metric, loss, check)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m in \u001b[39m\u001b[39m{\u001b[39;00mcheck\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m F1Weighted = \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mF1Weighted\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, flush\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    479\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m in \u001b[39m\u001b[39m{\u001b[39;00mcheck\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m F1Macro = \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mF1Macro\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, flush\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 481\u001b[0m wandb\u001b[39m.\u001b[39;49mlog({\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49md1, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmultiF1, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmultiRec, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmultiPrec, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmultiAcc})\n\u001b[1;32m    482\u001b[0m Metric\u001b[39m.\u001b[39mreset_metrics()\n\u001b[1;32m    483\u001b[0m \u001b[39mreturn\u001b[39;00m F1Weighted\n",
      "File \u001b[0;32m~/.conda/envs/featuregen/lib/python3.11/site-packages/wandb/sdk/lib/preinit.py:36\u001b[0m, in \u001b[0;36mPreInitCallable.<locals>.preinit_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpreinit_wrapper\u001b[39m(\u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m---> 36\u001b[0m     \u001b[39mraise\u001b[39;00m wandb\u001b[39m.\u001b[39mError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mYou must call wandb.init() before \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m()\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mError\u001b[0m: You must call wandb.init() before wandb.log()"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(big_batch=23 , num_steps=1)\n",
    "trainer.evaluate(whisper, df_test, Metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " in test \n",
    " Acc = \n",
    "0.44938650727272034 \n",
    "\n",
    "\n",
    " in test \n",
    " Prec = \n",
    "0.3184402287006378 \n",
    "\n",
    "\n",
    " in test \n",
    " Rec = \n",
    "0.31386637687683105 \n",
    "\n",
    "\n",
    " in test \n",
    " F1Weighted = \n",
    "0.45675623416900635 \n",
    "\n",
    "\n",
    " in test \n",
    " F1Macro = \n",
    "0.30369332432746887 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weighted F1 score is 0.6964451231409771\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Your confusion matrix\n",
    "cm = np.array([[651, 238,  52, 232,  53,  11,  19],\n",
    "        [108, 189,  20,  58,  12,  10,   5],\n",
    "        [ 63,  56,  87,  52,  10,   6,   7],\n",
    "        [ 66,  46,  19, 192,  11,   5,   5],\n",
    "        [ 52,  36,  12,  53,  46,   4,   5],\n",
    "        [  9,  13,   4,  28,   6,   4,   3],\n",
    "        [ 15,   8,   0,  16,   6,   2,   3]])\n",
    "\n",
    "# Convert the confusion matrix into actual and predicted labels\n",
    "y_true = np.repeat(np.arange(cm.shape[0]), np.sum(cm, axis=1))\n",
    "y_pred = np.repeat(np.arange(cm.shape[1]), np.sum(cm, axis=0))\n",
    "\n",
    "# Calculate weighted F1 score\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "print(f\"The weighted F1 score is {f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Loading in out model, but index out encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x1 = torch.Tensor([2])\n",
    "x2 = torch.Tensor([4])\n",
    "x3 = torch.Tensor([3])\n",
    "\n",
    "torch.mean(torch.stack([x1 , x2 , x3]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "featuregen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
